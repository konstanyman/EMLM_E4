{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Konsta Nyman\n",
    "\n",
    "Student number: 523834\n",
    "\n",
    "Student email: kokany@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, how cross-validation should be performed in the given scenario and why  your cross-validation will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 21 February 2024 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. Currently I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have a list of over 100.000 potential drug molecules, but their affinities still need to be verified in the lab. Obviously I do not have the resources to measure all the possible drug-target pairs, so I need to prioritise. I have decided to do this with the use of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had made in the lab, which comprise of all the 77 target proteins of interest but only 59 different drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of the remaining drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether I am wasting my lab resources by using my model.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "\n",
    "# The estimation described in the letter failed because of dependencies between the observations in the pair-input data. Some pairs share objects and are therefore dependent on each other.\n",
    "# For example the pair-input observation 3 (\"D6\" \"T58\") shares the same drug with the observation 38 (\"D6\" \"T41\"). When either of these pair-input observations or any other observations that\n",
    "# share objects with training set objects are taken to be the test set, an issue occurs. This optimistically biases the estimation because the test and training sets contain pairs that share \n",
    "# the same object and the independency assumption does not hold. \n",
    "\n",
    "\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "\n",
    "# There are usually four types of observations in pair-input data. This problem only contains observations of Type A and Type B, since all target proteins are used in the sample. We can call the \n",
    "# drugs the 1st member of the pair and the target proteins the 2nd member. Type A observations include pair-input observations where both members are included in the sample, even if the exact pair \n",
    "# isn't in the sample. The performance is expected to be better on Type A observations. Performance is expected to be worse on Type B observations which include all pairings where only the 2nd \n",
    "# member is part of the sample. In this case they include all pairings that feature any other drug than any of the 59 ones included in the sample, since all the proteins are in-sample data. There\n",
    "# being over 100 000 potential drugs, Type B pairings form the vast majority of the parings. The estimate received already is reliable for Type A pairings since the data naturally includes only \n",
    "# Type A pairs, but we need to alter evaluation methods to get a reliable generalized performance estimate for Type B parings.\n",
    "\n",
    "# When performing leave-one-out cross-validation to estimate the performance of Type B observations, we must ignore any training set pairs that share the 1st member with the test set pair. This \n",
    "# gives a reliable estimate of the performance also on the generalized data since the dependencies in the data are considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis.\n",
    "\n",
    "### Append unique values to the list ###\n",
    "# list: list to be appended to\n",
    "# value: value to be appended to the list\n",
    "def append_unique(list, value):\n",
    "    if value not in list:\n",
    "        list.append(value)\n",
    "\n",
    "### Calculating C-index ###\n",
    "# y: array containing true values.\n",
    "# yp: array containing the predicted values.\n",
    "def cindex(y, yp):\n",
    "    n = 0\n",
    "    h_num = 0 \n",
    "    for i in range(0, len(y)):\n",
    "        t = y[i]\n",
    "        p = yp[i]\n",
    "        for j in range(i+1, len(y)):\n",
    "            nt = y[j]\n",
    "            np = yp[j]\n",
    "            if (t != nt): \n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt): \n",
    "                    h_num += 1\n",
    "                elif (p == np):\n",
    "                    h_num += 0.5\n",
    "    return h_num/n\n",
    "\n",
    "# form training set for test object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_df: (400, 67)\n"
     ]
    }
   ],
   "source": [
    "# Read input.data\n",
    "\n",
    "input_df = pd.read_csv('input.data',\n",
    "                       sep=' ',\n",
    "                       header=None)\n",
    "print(f\"Shape of input_df: {input_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output_df: (400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Read output.data\n",
    "\n",
    "output_df = pd.read_csv('output.data',\n",
    "                       header=None)\n",
    "print(f\"Shape of output_df: {output_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pairs_df: (400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read pairs.data\n",
    "\n",
    "pairs_df = pd.read_csv('pairs.data',\n",
    "                       sep=' ',\n",
    "                       header=None)\n",
    "print(f\"Shape of pairs_df: {pairs_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index for Type B observations: 0.51968671679198\n"
     ]
    }
   ],
   "source": [
    "# Implement and run the requested cross-validation. Report and interpret its results.\n",
    "\n",
    "# create leave-one-out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# create knn model with 10 neighbors\n",
    "knn_10 = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# create list to store predictions\n",
    "y_predictions = []\n",
    "\n",
    "# loo split\n",
    "for train_index, test_index in loo.split(input_df):\n",
    "    X_train, X_test = input_df.iloc[train_index], input_df.iloc[test_index]\n",
    "    y_train, y_test = output_df.iloc[train_index], output_df.iloc[test_index]\n",
    "\n",
    "    # exclude all instances that share the 1st member of the pair\n",
    "    drop_indexes = []\n",
    "    for j in train_index:\n",
    "        if pairs_df.iloc[test_index[0], 0] == pairs_df.iloc[j, 0]:\n",
    "            append_unique(drop_indexes, j)\n",
    "    X_train = X_train.drop(drop_indexes)\n",
    "    y_train = y_train.drop(drop_indexes)\n",
    "\n",
    "    # fit k-NN model\n",
    "    knn_10.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    preds = knn_10.predict(X_test)\n",
    "    y_predictions.append(preds) #append predicted value to list\n",
    "\n",
    "# calculate c-index\n",
    "c_index_type_b = cindex(output_df.to_numpy(), y_predictions)\n",
    "\n",
    "# print result\n",
    "print(f\"C-index for Type B observations: {c_index_type_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index for Type A observations: 0.8300062656641604\n"
     ]
    }
   ],
   "source": [
    "# Original leave-one-out cross-validation for Type A \n",
    "\n",
    "# create list to store predictions\n",
    "y_predictions = []\n",
    "\n",
    "# loo split\n",
    "for train_index, test_index in loo.split(input_df):\n",
    "    X_train, X_test = input_df.iloc[train_index], input_df.iloc[test_index]\n",
    "    y_train, y_test = output_df.iloc[train_index], output_df.iloc[test_index]\n",
    "\n",
    "    # fit k-NN model\n",
    "    knn_10.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    preds = knn_10.predict(X_test)\n",
    "    y_predictions.append(preds) #append predicted value to list\n",
    "\n",
    "# calculate c-index\n",
    "c_index_type_a = cindex(output_df.to_numpy(), y_predictions)\n",
    "\n",
    "# print result\n",
    "print(f\"C-index for Type A observations: {c_index_type_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation for the performance on generalized data is very poor: 0.5197. This is a reliable estimate for any other drugs than the ones measured in the sample. I also got a lower performance estimate for Type A than you: 0.8300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
